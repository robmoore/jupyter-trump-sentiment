{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis with the Spark NLP Library\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook was developed using the [all-spark-notebook](https://github.com/jupyter/docker-stacks/tree/master/all-spark-notebook) and should work without modification in that environment.\n",
    "\n",
    "Earlier this year, I produced a [similar notebook](https://www.zepl.com/viewer/notebooks/bm90ZTovL3JvYm9yYXRpdmUvVHdpdHRlci1TZW50aW1lbnQtRXhhbXBsZS9hNTlmZjFkYTAzY2Y0ZWY0YTg5MWRlNjZkMWFlM2I0My9ub3RlLmpzb24) using [Zeppelin](https://zeppelin.apache.org/). In that project, I used the [Stanford CoreNLP](https://stanfordnlp.github.io/CoreNLP/) library to analyze sentiment of a Twitter stream of tweets about Donald Trump. The CoreNLP library is not specific to Spark but is written in Java so it's trivial to use it from within Spark. However, recent investigation into the current NLP space in the Spark ecosystem unearthed the recently released [NLP library](http://nlp.johnsnowlabs.com/index.html) from [John Snow Labs](http://www.johnsnowlabs.com). The library includes a sentiment analyzer which utilizes a novel approach based on the [research](http://arxiv.org/abs/1305.6143) and [code](https://github.com/vivekn/sentiment) produced by Vivek Narayanan et al. In the paper, the authors claim an 88% accuracy on sentiment prediction of reviews from the Internet Movie Database (IMDb).\n",
    "\n",
    "As I considered this project, I came across a [data set of tweets about Trump](https://www.kaggle.com/ahsanijaz/trumptweets) which includes 4600 tweets collected on August 17, 2015. The data set stood out because the tweets were manually labeled as positive or negative. Of course, having pre-labeled data has proven tremedously helpful in evaluating a supervised sentiment analyzer as the labor-intensive work of providing classified data has already been performed by the provider (`ahsanijaz`). \n",
    "\n",
    "In comparison to the IMDB data set of 25000 reviews, the tweet data set is much more limited in number and in length of text. Nevertheless, in this notebook the analysis of the tweet data set resulted in an accuracy of 88.1%. As the Vivekn et al approach is based on a Naive Bayes model which lends itself to shorter text according to [prior research](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf), it appears to be a good choice for analyzing this data.\n",
    "\n",
    "One factor that made a significant difference in the performance of the model is the approach taken here of not removing duplicate data from the training set. If duplicate data is removed from the set the accuracy drops to 83.7%. Duplicate tweets result primarily from the processing approach taken below in which retweets are represented in the data. Furthermore, the common indicators of a retweet ('RT' and 'via') have been removed from the tweets which results in a modest futher redundancy. It may be the case that the redundancy helps reinforce the general mood of the population and thereby helps shift the weighting in a beneficial way. However, it also seems likely that the approach may cause overfitting of the data as it is more probable that duplicate tweets will appear in both the training and test sets. In this notebook, I have not tested this hypothesis but it certainly would be beneficial in getting better confidence in the resulting model.\n",
    "\n",
    "### Preparation details\n",
    "\n",
    "Before I could begin to analyze the data, data wrangling was necessary. The source file (`trumptweets.csv`) appears to have a Windows-1252 encoding and oddly has fewer columns defined than the data it describes. While the data is loaded using the Windows-1252 encoding, encoding artifacts remain that could influence the analysis of the tweets and may be worth further investigation.\n",
    "\n",
    "In order to align the data with the defined columns, I add a nonce header value (`X_copy`). Furthermore, the Spark CSV parser behaves in a subtlely different way when periods (`.`) exist in the column names so I modified these as well. Finally, the original data used backslashes to escape quotes (`\\\"`) rather than the more common approach of using double quotes (`\"\"`) so I substituted the former with the later so that the Spark CSV parser would work correctly.\n",
    "\n",
    "As I examined the data, I came across many instances of peculiar text like `<ed><U+00A0><U+00BD><ed><U+00B8><U+0089>`. After much fr research, I was able to determine that the text actually was an R artifact (specifically, it seems that the data was pulled from Twitter using the R ‚ÄòtwitteR‚Äô package) and are the result of R translating emojis to text (see [Emoticons decoder for social media sentiment analysis in R](http://opiateforthemass.es/articles/emoticons-in-R/) and [Twitter emoji encoding problems with twitteR and R](https://stackoverflow.com/questions/37999896/twitter-emoji-encoding-problems-with-twitter-and-r) for details). I found a [resource](https://github.com/today-is-a-good-day/emojis/blob/master/emojis.csv) that provided an exhaustive list of emojis in this format and which I was able to use to map to text equivalents (eg, üòä to \"smiling face with smiling eyes\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating copy of trumptweet.csv with modifications\n",
      "Fetching emojis.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -f trumptweet_mod.csv ]; then\n",
    "    echo \"Creating copy of trumptweet.csv with modifications\"\n",
    "    iconv -f CP1252 -t UTF-8 trumptweet.csv > trumptweet_mod.csv # Convert to UTF-8\n",
    "    sed -i 's/\"X\",/\"X\",\"X_copy\",/' trumptweet_mod.csv # Add new column to header to align header with data\n",
    "    sed -i 's/\"X.1\",/\"X_1\",/' trumptweet_mod.csv # Spark reader behaves oddly when like dots are in column names\n",
    "    sed -i 's/\\\\\"/\"\"/g' trumptweet_mod.csv # Use standard quote escapes for CSV rather than backslashes\n",
    "else\n",
    "    echo \"trumptweet_mod.csv already exists\"\n",
    "fi\n",
    "\n",
    "if [ ! -f emojis.csv ]; then\n",
    "    echo \"Fetching emojis.csv\"\n",
    "    wget -q http://raw.githubusercontent.com/today-is-a-good-day/Emoticons/master/emojis.csv\n",
    "else\n",
    "    echo \"emojis.csv already exists\"  \n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by installing the Spark NLP library into the environment as it is not included in the Jupyter environment noted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Load Spark NLP package as it's not included in all-spark-notebook\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages JohnSnowLabs:spark-nlp:1.2.3 pyspark-shell'\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "#conf.set(\"spark.executor.memory\", \"4g\")\n",
    "conf.set(\"spark.driver.memory\", \"2g\")\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]', conf = conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains linefeeds so the `multiLine` parameter was required to process the entire data set. As is seen below, the data contains a roughly equal number of positive and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Class|count|\n",
      "+-----+-----+\n",
      "|    0| 2262|\n",
      "|    1| 2340|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use modified version of the data\n",
    "labeled_data = spark.read.csv(\"trumptweet_mod.csv\", header = True, escape = '\"', mode = \"FAILFAST\", multiLine = \"true\")\n",
    "\n",
    "# Show breakdown of positive and negative tweets\n",
    "labeled_data.groupBy('Class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the `html` library to translate HTML entities to their text equivalents (eg, `&gt;`, `&amp;`, etc).\n",
    "\n",
    "Additionally, I perform the following normalizations on the data :\n",
    "\n",
    "- Remove `RT` and `via`\n",
    "- Remove the 'at' character (`@`) from user references (eg, `@realDonaldTrump`)\n",
    "- Remove URLs\n",
    "- Convert R-style emoji references (eg, `<ed><U+00A0>...`) to their text equivalents\n",
    "- Removed stray leading characters (`.` and `,`)\n",
    "- Removed whitespace and beginning and end of tweet\n",
    "- Removed any entries that resulted in empty text after the above processing\n",
    "- Removed all columns except for the normalized text and the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           norm_text|Class|\n",
      "+--------------------+-----+\n",
      "|GOPBlackChick: Il...|    1|\n",
      "|CNN is there any ...|    0|\n",
      "|KurtSchlichter: C...|    0|\n",
      "|ajpeacemaker mdja...|    0|\n",
      "|THE TRUMP IMMIGRA...|    1|\n",
      "|CNNPolitics: Chri...|    0|\n",
      "|Morning_Joe Not a...|    1|\n",
      "|ThePatriot143: Co...|    0|\n",
      "|Trump is correct ...|    1|\n",
      "|\"I'm going to pre...|    1|\n",
      "|I really hope peo...|    0|\n",
      "|Trump is claiming...|    0|\n",
      "|marclamonthill: L...|    1|\n",
      "|BOOM ‚Äì Univision ...|    1|\n",
      "|GeoScarborough I ...|    1|\n",
      "|AlexBlackStars Dm...|    0|\n",
      "|charlescwcooke: T...|    0|\n",
      "|mdabbss: Donald t...|    0|\n",
      "|A little surprise...|    1|\n",
      "|Salon: Trump is t...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize tweets\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import trim\n",
    "from pyspark.sql.functions import udf\n",
    "import re\n",
    "import html\n",
    "\n",
    "rt_regex = r\"^RT[ :]\" # Drop RT\n",
    "via_regex = \"^Via | via \" # Likewise, remove via references while preserving succeeding hashtags\n",
    "user_regex = r\"@(?=\\S+)\" # Remove @ but leave user value\n",
    "url_regex = r\"http\\S+\" # Drop URLs\n",
    "hashtag_regex = r\"#(?=\\S+)\" # Remove hashtag itself but leave tag value\n",
    "space_etc_regex = r\"^[\\.,]|\\s{2,}|\\n\" # Remove extra spaces, linefeeds and leading periods or commas.\n",
    "\n",
    "# Remove RT, vias, @s, URLs, line feeds, etc\n",
    "uber_regex = \"|\".join([url_regex, rt_regex, via_regex, user_regex, hashtag_regex])\n",
    "\n",
    "emoji_data = spark.read.csv(\"emojis.csv\", header = True, sep = \";\")\n",
    "emoji_data_list = map(lambda row: row.asDict(), emoji_data.collect())\n",
    "emoji_data_dict = { row['ftu8']: row for row in emoji_data_list }\n",
    "\n",
    "r_unicode_regex = re.compile(r\"<e[a-f0-9]>\\S+>\")\n",
    "r_unicode_pieces_regex = re.compile(r\"<e[a-f]><U\\+[A-F0-9]{4}><U\\+[A-F0-9]{4}>\")\n",
    "\n",
    "def replace_emojis(s, r_unicode):\n",
    "  r_unicode_matches = r_unicode_pieces_regex.findall(r_unicode)\n",
    "  for n in range(len(r_unicode_matches), 0, -1):\n",
    "    r_unicode_key = \"\".join(r_unicode_matches[0:n]).replace(\"U+00\", \"\").lower()\n",
    "    if r_unicode_key in emoji_data_dict:\n",
    "      unicodes = emoji_data_dict[r_unicode_key].get(\"unicode\").split()\n",
    "      unicode = \"\".join(map(lambda u: f\"<{u}>\", unicodes))\n",
    "      to_be_replaced = \"\".join(r_unicode_matches[0:n])\n",
    "      s = s.replace(to_be_replaced, unicode) # Make translated value a sentence.\n",
    "      break\n",
    "  return s\n",
    "\n",
    "# def replace_emojis(s, r_unicode):\n",
    "#   r_unicode_matches = r_unicode_pieces_regex.findall(r_unicode)\n",
    "#   for n in range(len(r_unicode_matches), 0, -1):\n",
    "#     r_unicode_key = \"\".join(r_unicode_matches[0:n]).replace(\"U+00\", \"\").lower()\n",
    "#     if r_unicode_key in emoji_data_dict:\n",
    "#       text = emoji_data_dict[r_unicode_key].get(\"EN\")\n",
    "#       to_be_replaced = \"\".join(r_unicode_matches[0:n])\n",
    "#       s = s.replace(to_be_replaced, f\" {text}. \") # Make translated value a sentence.\n",
    "#       break\n",
    "#   return s\n",
    "\n",
    "def fix_emojis(s):\n",
    "  is_done = False\n",
    "  while r_unicode_regex.search(s) is not None and is_done is False:\n",
    "    s_prior = s\n",
    "    for match in r_unicode_regex.finditer(s):        \n",
    "      m = match.group()\n",
    "      s = replace_emojis(s, m) \n",
    "      is_done = s == s_prior\n",
    "  return s\n",
    "\n",
    "# Replace R-style emoji encoding with text equivalent\n",
    "fix_emojis_udf = udf(fix_emojis)\n",
    "# Convert <U+00??> references to Unicode characters\n",
    "fix_unicode_udf = udf(lambda s: re.sub(r'<U\\+([0-9a-fA-F]+)>', lambda m: chr(int(m.group(1),16)), s))\n",
    "fix_smart_quotes_etc_udf = udf(lambda s: s.replace( \"‚Äô\", \"'\" ).replace( \"‚Äú\", '\"' ).replace( \"‚Äù\", '\"' ) \\\n",
    "                           .replace(\"‚Ä¶\", \"...\").replace(\"‚Äò\",\"'\").replace(\"‚ÅâÔ∏è\", \"!?\").replace(\"‚Äº\", \"!!\") \\\n",
    "                           .replace(\"‚ù§\", \"love\").replace(\"‚ô•\", \"love\").replace(\"&039;\", \"\\\"\"))\n",
    "unescape_html_udf = udf(lambda s: html.unescape(s))\n",
    "\n",
    "#labeled_data = labeled_data.filter(labeled_data.lang == \"en\") # Drop any entries in languages other than English\n",
    "labeled_data = labeled_data.withColumn(\"norm_text\", regexp_replace(\"text\", uber_regex, \"\"))\n",
    "labeled_data = labeled_data.withColumn(\"norm_text\", fix_emojis_udf(\"norm_text\"))\n",
    "#labeled_data = labeled_data.withColumn(\"norm_text\", regexp_replace(\"norm_text\", \"<U\\+[0-9a-fA-F]+>\", \"\"))\n",
    "labeled_data = labeled_data.withColumn(\"norm_text\", fix_unicode_udf(\"norm_text\"))\n",
    "labeled_data = labeled_data.withColumn(\"norm_text\", unescape_html_udf(\"norm_text\"))\n",
    "labeled_data = labeled_data.withColumn(\"norm_text\", fix_smart_quotes_etc_udf(\"norm_text\"))\n",
    "labeled_data = labeled_data.withColumn(\"norm_text\", trim(regexp_replace(\"norm_text\", space_etc_regex, \" \")))\n",
    "\n",
    "labeled_data = labeled_data.filter(labeled_data.norm_text != '') # Drop any text that is now empty from actions above\n",
    "labeled_data = labeled_data.select(\"norm_text\", \"Class\") # Drop most of the data as isn't used\n",
    "\n",
    "labeled_data.coalesce(1).write.mode(\"overwrite\").csv(\"labeled-data.csv\", header = True, escape = \"\\\"\")\n",
    "\n",
    "labeled_data.cache()\n",
    "labeled_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vivekn annotator requires separate files for both positive and negative training data. While there is not much documentation on the expected input, my attempts to utilize such an approach were not successful unless I removed the any metadata files (eg, `_SUCCESS` and `_SUCCESS.crc`) from the paritioned files created by Spark. As a result, I resorted to a hybrid approach of writing out the training data using the standard Spark API and then deleting problematic files by accessing the underlying Hadoop libraries directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data 80%/20% for training and testing\n",
    "train_data, test_data = labeled_data.randomSplit([0.8, 0.2], seed=71082)\n",
    " \n",
    "# Vivekn sentiment approach in SparkNLP below requires separate files for both positive and negative training data.\n",
    "# After much experimentation, not able to simple write to filesystem using Spark libraries\n",
    "# as it produces both the data file and metadata files that the Vivekn annotator cannot process\n",
    "# when simply indicating the directory where the file exists in the code below.\n",
    "def write_df(df, dirname, filename):\n",
    "    # Use Hadoop library directly to write to filesystem\n",
    "    Path = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "    FileSystem = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "    Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "\n",
    "    tmp_name = filename + \".tmp\"\n",
    "    # Write to a single file rather than multiple\n",
    "    df.coalesce(1).write.mode('overwrite').text(tmp_name)\n",
    "    \n",
    "    fs = FileSystem.get(Configuration())\n",
    "    fs.mkdirs(Path(dirname))\n",
    "    # Assume one file output\n",
    "    file = fs.globStatus(Path(tmp_name + \"/*.txt\"))[0].getPath();\n",
    "    fs.rename(file, Path(dirname + \"/\" + filename));\n",
    "    fs.delete(Path(tmp_name), True);\n",
    "    \n",
    "#train_data = train_data.distinct()    \n",
    "\n",
    "# split training data into positive/negative\n",
    "positive_data = train_data.filter(train_data.Class == \"1\").select(\"norm_text\")\n",
    "write_df(positive_data, \"train-data\", \"positive.txt\")\n",
    "\n",
    "negative_data = labeled_data.filter(train_data.Class == \"0\").select(\"norm_text\")\n",
    "negative_data = negative_data.distinct()\n",
    "write_df(negative_data, \"train-data\", \"negative.txt\")\n",
    "\n",
    "# remove duplicates\n",
    "#test_data = test_data.distinct()\n",
    "test_data.write.mode(\"overwrite\").parquet(\"test-data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment prediction\n",
    "\n",
    "Now that we have the training and test data ready to go, it's time to put it to use!\n",
    "\n",
    "After reading in the test data, we remove duplicate entries so as not to bias the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           norm_text|Class|\n",
      "+--------------------+-----+\n",
      "|\"Did you know tha...|    0|\n",
      "|\"I told you guys ...|    0|\n",
      "|\"In 24 days plus ...|    1|\n",
      "|\"PolitiFact: Dona...|    1|\n",
      "|'Dilbert' creator...|    0|\n",
      "|'I am Batman,' Tr...|    0|\n",
      "|08/17 1952: chess...|    0|\n",
      "|20 times Donald T...|    0|\n",
      "|2phonefranki: the...|    0|\n",
      "|2phonefranki: the...|    0|\n",
      "|7 ways the latest...|    1|\n",
      "|ABC: Donald Trump...|    1|\n",
      "|ABCPolitics: Dona...|    1|\n",
      "|ADobranic: Alfred...|    1|\n",
      "|ANY FAITH I HAD L...|    0|\n",
      "|Actually, if I we...|    1|\n",
      "|AdamBaldwin: BREA...|    1|\n",
      "|Adviser: Donald T...|    1|\n",
      "|Adviser: Donald T...|    1|\n",
      "|Adviser: Donald T...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in data produced earlier\n",
    "test_data = spark.read.parquet(\"test-data.parquet\")\n",
    "test_data.cache()\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now execute the NLP pipeline using the Vivekn annotator to create a model and make sentiment predictions on our test tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|           norm_text|Class|  finished_sentiment|\n",
      "+--------------------+-----+--------------------+\n",
      "|\"Did you know tha...|    0|    result->negative|\n",
      "|\"I told you guys ...|    0|    result->negative|\n",
      "|\"In 24 days plus ...|    1|result->positive@...|\n",
      "|\"PolitiFact: Dona...|    1|result->positive@...|\n",
      "|'Dilbert' creator...|    0|result->positive@...|\n",
      "|'I am Batman,' Tr...|    0|    result->negative|\n",
      "|08/17 1952: chess...|    0|result->positive@...|\n",
      "|20 times Donald T...|    0|    result->negative|\n",
      "|2phonefranki: the...|    0|    result->negative|\n",
      "|2phonefranki: the...|    0|    result->negative|\n",
      "|7 ways the latest...|    1|    result->negative|\n",
      "|ABC: Donald Trump...|    1|    result->positive|\n",
      "|ABCPolitics: Dona...|    1|    result->positive|\n",
      "|ADobranic: Alfred...|    1|result->positive@...|\n",
      "|ANY FAITH I HAD L...|    0|    result->negative|\n",
      "|Actually, if I we...|    1|result->positive@...|\n",
      "|AdamBaldwin: BREA...|    1|    result->negative|\n",
      "|Adviser: Donald T...|    1|    result->positive|\n",
      "|Adviser: Donald T...|    1|    result->positive|\n",
      "|Adviser: Donald T...|    1|    result->positive|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "\n",
    "document_assembler = DocumentAssembler().setInputCol(\"norm_text\")\n",
    "    \n",
    "sentence_detector = SentenceDetectorModel().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\")\n",
    "        \n",
    "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normal\")        \n",
    "        \n",
    "spell_checker = NorvigSweetingApproach().setInputCols([\"normal\"]).setOutputCol(\"spell\")\n",
    "  \n",
    "sentiment_detector = ViveknSentimentApproach().setInputCols([\"spell\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment\").setPositiveSource(\"train-data/positive.txt\") \\\n",
    "    .setNegativeSource(\"train-data/negative.txt\").setPruneCorpus(False)       \n",
    "    \n",
    "finisher = Finisher().setInputCols([\"sentiment\"]).setIncludeKeys(True)\n",
    "    \n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    normalizer,\n",
    "    spell_checker,\n",
    "    sentiment_detector,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "sentiment_data = pipeline.fit(test_data).transform(test_data)    \n",
    "sentiment_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline adds an extra column with an sentiment indicated for each sentence in the tweet. The value of the indication is either `result->positive` or `result->negative` and multiple sentences are represented with the repetition of these values delimited by `@`.  In order to get a single Boolean value for the tweet, we take the average of each sentiment indication and then round the result to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+---------------+\n",
      "|           norm_text|Class|  finished_sentiment|total_sentiment|\n",
      "+--------------------+-----+--------------------+---------------+\n",
      "|\"Did you know tha...|    0|    result->negative|              0|\n",
      "|\"I told you guys ...|    0|    result->negative|              0|\n",
      "|\"In 24 days plus ...|    1|result->positive@...|              1|\n",
      "|\"PolitiFact: Dona...|    1|result->positive@...|              1|\n",
      "|'Dilbert' creator...|    0|result->positive@...|              1|\n",
      "|'I am Batman,' Tr...|    0|    result->negative|              0|\n",
      "|08/17 1952: chess...|    0|result->positive@...|              1|\n",
      "|20 times Donald T...|    0|    result->negative|              0|\n",
      "|2phonefranki: the...|    0|    result->negative|              0|\n",
      "|2phonefranki: the...|    0|    result->negative|              0|\n",
      "|7 ways the latest...|    1|    result->negative|              0|\n",
      "|ABC: Donald Trump...|    1|    result->positive|              1|\n",
      "|ABCPolitics: Dona...|    1|    result->positive|              1|\n",
      "|ADobranic: Alfred...|    1|result->positive@...|              1|\n",
      "|ANY FAITH I HAD L...|    0|    result->negative|              0|\n",
      "|Actually, if I we...|    1|result->positive@...|              1|\n",
      "|AdamBaldwin: BREA...|    1|    result->negative|              0|\n",
      "|Adviser: Donald T...|    1|    result->positive|              1|\n",
      "|Adviser: Donald T...|    1|    result->positive|              1|\n",
      "|Adviser: Donald T...|    1|    result->positive|              1|\n",
      "+--------------------+-----+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from statistics import mean\n",
    "\n",
    "def sigmoid(s):\n",
    "    return 0 if s is None else round(mean(map(lambda x: 1 if (x == \"result->positive\") else 0, s.split(\"@\"))) + .01)\n",
    "\n",
    "sigmoid_udf = udf(sigmoid, IntegerType())\n",
    "\n",
    "sentiment_data = sentiment_data.withColumn(\"total_sentiment\", sigmoid_udf(\"finished_sentiment\"))\n",
    "sentiment_data.cache()\n",
    "sentiment_data.write.mode(\"overwrite\").parquet(\"sentiment-data.parquet\")\n",
    "sentiment_data.coalesce(1).write.mode(\"overwrite\").csv(\"sentiment-data.csv\", header = True, escape = \"\\\"\")\n",
    "sentiment_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we determine the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct classification percentage: 86.3% [750 of 869]\n",
      "True positive percentage: 86.4% [370 of 428]\n",
      "False positive percentage: 14.3% [61 of 428]\n",
      "True negative percentage: 86.2% [380 of 441]\n",
      "False negative percentage: 13.2% [58 of 441]\n"
     ]
    }
   ],
   "source": [
    "correct_count = sentiment_data.filter(sentiment_data.Class == sentiment_data.total_sentiment).count()\n",
    "total_count =  sentiment_data.count()\n",
    "\n",
    "print(f\"Total correct classification percentage: {correct_count / total_count:.1%} [{correct_count} of {total_count}]\")\n",
    "\n",
    "# False Pos %\n",
    "pos_count = sentiment_data.filter(sentiment_data.Class == 1).count()\n",
    "true_pos_count = sentiment_data.filter(sentiment_data.total_sentiment == 1).filter(sentiment_data.Class == 1).count()\n",
    "false_pos_count = sentiment_data.filter(sentiment_data.total_sentiment == 1).filter(sentiment_data.Class == 0).count()\n",
    "\n",
    "print(f\"True positive percentage: {true_pos_count/pos_count:.1%} [{true_pos_count} of {pos_count}]\")\n",
    "print(f\"False positive percentage: {false_pos_count/pos_count:.1%} [{false_pos_count} of {pos_count}]\")\n",
    "\n",
    "# False Neg %\n",
    "neg_count = sentiment_data.filter(sentiment_data.Class == 0).count()\n",
    "true_neg_count = sentiment_data.filter(sentiment_data.total_sentiment == 0).filter(sentiment_data.Class == 0).count()\n",
    "false_neg_count = sentiment_data.filter(sentiment_data.total_sentiment == 0).filter(sentiment_data.Class == 1).count()\n",
    "\n",
    "print(f\"True negative percentage: {true_neg_count/neg_count:.1%} [{true_neg_count} of {neg_count}]\")\n",
    "print(f\"False negative percentage: {false_neg_count/neg_count:.1%} [{false_neg_count} of {neg_count}]\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
