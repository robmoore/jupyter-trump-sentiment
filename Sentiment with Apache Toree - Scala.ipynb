{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking com.johnsnowlabs.nlp:spark-nlp_2.11:1.2.3 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps4361659222086788520/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps4361659222086788520/https/repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.11/1.2.3/spark-nlp_2.11-1.2.3.jar\n",
      "Marking org.apache.bahir:spark-streaming-twitter_2.11:2.2.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps4361659222086788520/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps4361659222086788520/https/repo1.maven.org/maven2/org/apache/bahir/spark-streaming-twitter_2.11/2.2.0/spark-streaming-twitter_2.11-2.2.0.jar\n",
      "Marking com.vdurmont:emoji-java:3.1.3 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps4361659222086788520/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps4361659222086788520/https/repo1.maven.org/maven2/com/vdurmont/emoji-java/3.1.3/emoji-java-3.1.3.jar\n"
     ]
    }
   ],
   "source": [
    "%AddDeps com.johnsnowlabs.nlp spark-nlp_2.11 1.2.3\n",
    "%AddDeps org.apache.bahir spark-streaming-twitter_2.11 2.2.0\n",
    "%AddDeps com.vdurmont emoji-java 3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark =  SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+\n",
      "|itemid|sentiment|                text|\n",
      "+------+---------+--------------------+\n",
      "|393940|        1|@Natasja_Cupcake ...|\n",
      "|393941|        1|@Natasja_Cupcake ...|\n",
      "|393942|        0|@Natasja_Cupcake ...|\n",
      "|393943|        0|@Natasja_Cupcake ...|\n",
      "|393944|        1|@Natasja_Cupcake ...|\n",
      "|393945|        1|@renegade37918  I...|\n",
      "|393946|        0|@renegadejk529 i ...|\n",
      "|393947|        1|@RenegadeScribe O...|\n",
      "|393948|        0|@RenegadeSOA513 ....|\n",
      "|393949|        1|@RenegadeSOA513 J...|\n",
      "|393950|        0|@RenegadeSOA513 L...|\n",
      "|393951|        1|@RenegadEuphoriX ...|\n",
      "|393952|        1|@RenegadeVyper DO...|\n",
      "|393953|        1|@Renegal Nah, it ...|\n",
      "|393954|        1|@Renegat Ñ?ÑƒÐ¿Ðµ...|\n",
      "|393955|        1|@reneilim don't f...|\n",
      "|393956|        1|@renelannte mouse...|\n",
      "|393957|        0|@renemonney Jam W...|\n",
      "|393958|        0|@renemonster i wa...|\n",
      "|393959|        1|  @renems enviei rs |\n",
      "+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Load the input data to be annotated\n",
    "val data = spark.read.parquet(\"sentiment.parquet\").limit(1000)\n",
    "data.cache()\n",
    "data.count()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.johnsnowlabs.nlp._\n",
    "import com.johnsnowlabs.nlp.annotators._\n",
    "import org.apache.spark.ml.{Pipeline,PipelineModel}\n",
    "import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetectorModel\n",
    "import com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingApproach\n",
    "import com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach\n",
    "\n",
    "val documentAssembler = new DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "val sentenceDetector = new SentenceDetectorModel().setInputCols(Array(\"document\")).setOutputCol(\"sentence\")\n",
    "\n",
    "val tokenizer = new RegexTokenizer().setInputCols(Array(\"sentence\")).setOutputCol(\"token\")\n",
    "        \n",
    "val normalizer = new Normalizer().setInputCols(Array(\"token\")).setOutputCol(\"normal\")        \n",
    "        \n",
    "val spellChecker = new NorvigSweetingApproach().setInputCols(Array(\"normal\")).setOutputCol(\"spell\")\n",
    "\n",
    "// When training on small data you may want to disable this to not cut off infrequent words\n",
    "val sentimentDetector = new ViveknSentimentApproach().setInputCols(Array(\"spell\", \"sentence\")).setOutputCol(\"sentiment\").setPositiveSourcePath(\"vivekn/positive\").setNegativeSourcePath(\"vivekn/negative\").setCorpusPrune(false)\n",
    "    \n",
    "val finisher = new Finisher().setInputCols(Array(\"sentiment\")).setIncludeKeys(true) //.setCleanAnnotations(false)\n",
    "    \n",
    "val pipeline = new Pipeline().setStages(Array(documentAssembler, sentenceDetector, tokenizer, normalizer, spellChecker, sentimentDetector, finisher))\n",
    "\n",
    "val sentimentData = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|itemid|                text|  finished_sentiment|\n",
      "+------+--------------------+--------------------+\n",
      "|393940|@Natasja_Cupcake ...|result->positive@...|\n",
      "|393941|@Natasja_Cupcake ...|    result->positive|\n",
      "|393942|@Natasja_Cupcake ...|result->positive@...|\n",
      "|393943|@Natasja_Cupcake ...|result->positive@...|\n",
      "|393944|@Natasja_Cupcake ...|    result->positive|\n",
      "|393945|@renegade37918  I...|    result->positive|\n",
      "|393946|@renegadejk529 i ...|    result->positive|\n",
      "|393947|@RenegadeScribe O...|result->positive@...|\n",
      "|393948|@RenegadeSOA513 ....|result->positive@...|\n",
      "|393949|@RenegadeSOA513 J...|    result->positive|\n",
      "|393950|@RenegadeSOA513 L...|    result->positive|\n",
      "|393951|@RenegadEuphoriX ...|result->positive@...|\n",
      "|393952|@RenegadeVyper DO...|result->positive@...|\n",
      "|393953|@Renegal Nah, it ...|    result->positive|\n",
      "|393954|@Renegat Ñ?ÑƒÐ¿Ðµ...|    result->positive|\n",
      "|393955|@reneilim don't f...|result->positive@...|\n",
      "|393956|@renelannte mouse...|result->positive@...|\n",
      "|393957|@renemonney Jam W...|    result->negative|\n",
      "|393958|@renemonster i wa...|result->negative@...|\n",
      "|393959|  @renems enviei rs |    result->positive|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- itemid: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- finished_sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentData.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(xs: Iterable[Int]) = xs.sum / xs.size\n",
    "// column 2 == finished_sentiment\n",
    "sentimentData.take(120).map(r => r.getString(2).split('@').map(s => if (s == \"result->positive\") 1 else 0)).map(a => sigmoid(a)).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.write.overwrite.save(\"./ps\")\n",
    "pipeline.fit(data).write.overwrite.save(\"./ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_725777fdacdb"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline.read.load(\"./ps\")\n",
    "PipelineModel.read.load(\"./ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
