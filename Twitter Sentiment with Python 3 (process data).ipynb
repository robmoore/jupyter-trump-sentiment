{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages JohnSnowLabs:spark-nlp:1.2.3 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "#conf.set(\"spark.executor.memory\", \"4g\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf = conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[norm_text: string, Class: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = spark.read.parquet(\"test-data.parquet\")\n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|           norm_text|Class|  finished_sentiment|\n",
      "+--------------------+-----+--------------------+\n",
      "|1/3 \"The presiden...|    0|    result->negative|\n",
      "|Donald Trump cont...|    1|result->positive@...|\n",
      "|Halperin: Trump R...|    1|    result->positive|\n",
      "|I've listened to ...|    0|result->negative@...|\n",
      "|Maher: I Don't Al...|    1|    result->positive|\n",
      "|Watched the inter...|    1|result->negative@...|\n",
      "|Who the he'll wan...|    0|result->negative@...|\n",
      "|timisteve Adviser...|    1|result->positive@...|\n",
      "|I wonder if Donal...|    1|    result->negative|\n",
      "|Rush continues ta...|    1|result->negative@...|\n",
      "|Trump sayshe's go...|    0|result->negative@...|\n",
      "|Trump would be th...|    1|result->negative@...|\n",
      "|We can only hope....|    1|result->negative@...|\n",
      "|realDonaldTrump H...|    0|    result->negative|\n",
      "|Donald Trump talk...|    0|    result->negative|\n",
      "|More striking? Re...|    1|result->negative@...|\n",
      "|Scott Walker: Don...|    1|    result->positive|\n",
      "|The Trump thing h...|    0|result->negative@...|\n",
      "|Trump defines his...|    1|    result->positive|\n",
      "|Wonder if has see...|    1|result->positive@...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "\n",
    "document_assembler = DocumentAssembler().setInputCol(\"norm_text\")\n",
    "    \n",
    "sentence_detector = SentenceDetectorModel().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\")\n",
    "        \n",
    "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normal\")        \n",
    "        \n",
    "spell_checker = NorvigSweetingApproach().setInputCols([\"normal\"]).setOutputCol(\"spell\")\n",
    "        \n",
    "# sentiment_detector = ViveknSentimentApproach().setInputCols([\"spell\", \"sentence\"]) \\\n",
    "#     .setOutputCol(\"sentiment\").setPositiveSource(\"trumptweet/positive/1.txt\") \\\n",
    "#     .setNegativeSource(\"trumptweet/negative/1.txt\").setPruneCorpus(False)\n",
    "\n",
    "sentiment_detector = ViveknSentimentApproach().setInputCols([\"spell\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment\").setPositiveSource(\"train-data.txt/positive.txt\") \\\n",
    "    .setNegativeSource(\"train-data.txt/negative.txt\").setPruneCorpus(False)   \n",
    "    \n",
    "finisher = Finisher().setInputCols([\"sentiment\"]).setIncludeKeys(True)\n",
    "    \n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    normalizer,\n",
    "    spell_checker,\n",
    "    sentiment_detector,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "sentiment_data = pipeline.fit(test_data).transform(test_data)    \n",
    "sentiment_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[norm_text: string, Class: string, finished_sentiment: string, total_sentiment: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from statistics import mean\n",
    "\n",
    "def sigmoid(s):\n",
    "    return 0 if s is None else round(mean(map(lambda x: 1 if (x == \"result->positive\") else 0, s.split(\"@\"))) + .01)\n",
    "\n",
    "sigmoid_udf = udf(sigmoid, IntegerType())\n",
    "\n",
    "sentiment_data = sentiment_data.withColumn(\"total_sentiment\", sigmoid_udf(\"finished_sentiment\"))\n",
    "sentiment_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = sentiment_data.filter(sentiment_data.Class == sentiment_data.total_sentiment).count()\n",
    "total_count =  sentiment_data.count()\n",
    "correct_count / total_count"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
