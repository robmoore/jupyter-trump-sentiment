{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages JohnSnowLabs:spark-nlp:1.2.3 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = spark.read.csv(\"trumptweet-mod.csv\", header = True, escape = '\"')\n",
    "labeled_data = labeled_data.select(\"text\", \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Class|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeled_data = labeled_data.filter((labeled_data.Class == '0') | (labeled_data.Class == '1'))\n",
    "labeled_data.select('Class').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize tweets\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import trim\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "user_regex = r\"@\\S+\"\n",
    "url_regex = r\"http[s]?://\\S+\"\n",
    "hashtag_regex = r\"#\\S+\"\n",
    "space_regex = r\"\\s{2,}|\\n\"\n",
    "\n",
    "#import emot\n",
    "#def strip_emo(text):\n",
    "#    for data in emot.emoji(text):\n",
    "#        text = text.replace(data['value'], '')   \n",
    "#    for data in emot.emoticons(text):\n",
    "#        text = text.replace(data['value'], '')\n",
    "#    return text\n",
    "#\n",
    "#strip_emo_udf = udf(strip_emo, StringType())\n",
    "\n",
    "rt_regex = r\"(?=\\s?)(RT)(?=\\s?)\"\n",
    "user_regex = r\"@\\S+\"\n",
    "url_regex = r\"http[s]?:\\/\\/\\S+\"\n",
    "hashtag_regex = r\"#\\S+\"\n",
    "space_regex = r\"\\s{2,}|\\n\"\n",
    "\n",
    "# TODO: Remove <ed><U+hex>\n",
    "# TODO: Allow hashtags\n",
    "# TODO: Allow users?\n",
    "\n",
    "# Remove RT, users (@foo), URLs, and duplicate space\n",
    "uber_regex =  \"|\".join([rt_regex, url_regex, space_regex, user_regex, hashtag_regex])#, user_regex, hashtag_regex])\n",
    "\n",
    "#labeled_data = labeled_data.withColumn(\"norm_text\", trim(strip_emo_udf(regexp_replace(\"text\", uber_regex, \"\"))))\n",
    "labeled_data = labeled_data.withColumn(\"norm_text\", trim(regexp_replace(\"text\", uber_regex, \"\")))\n",
    "labeled_data = labeled_data.filter(labeled_data.norm_text != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|                text|Class|           norm_text|\n",
      "+--------------------+-----+--------------------+\n",
      "|RT @GOPBlackChick...|    1|Illegals must be ...|\n",
      "|RT @KurtSchlichte...|    0|- The GOP Establi...|\n",
      "|@ajpeacemaker @md...|    0|So much stupid go...|\n",
      "|THE TRUMP IMMIGRA...|    1|THE TRUMP IMMIGRA...|\n",
      "|RT @CNNPolitics: ...|    0|Christie on Donal...|\n",
      "|@Morning_Joe Not ...|    1|Not a  fan, but h...|\n",
      "|RT @ThePatriot143...|    0|Court Has To Step...|\n",
      "|Trump is correct ...|    1|Trump is correct ...|\n",
      "|\"I'm going to pre...|    1|\"I'm going to pre...|\n",
      "|I really hope peo...|    0|I really hope peo...|\n",
      "|Trump is claiming...|    0|Trump is claiming...|\n",
      "|RT @marclamonthil...|    1|Latest poll has T...|\n",
      "|BOOM ' Univision ...|    1|BOOM ' Univision ...|\n",
      "|@GeoScarborough I...|    1|I am now all in f...|\n",
      "|RT @charlescwcook...|    0|Today's Trump pos...|\n",
      "|RT @mdabbss: Dona...|    0|Donald trump the ...|\n",
      "|A little surprise...|    1|A little surprise...|\n",
      "|RT @Salon: Trump ...|    0|Trump is the last...|\n",
      "|RT @aduanebrown: ...|    1|Mr. Trump has don...|\n",
      "|RT @washingtonpos...|    1|Why Donald Trump ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break up into separate parts\n",
    "train_data, test_data = labeled_data.randomSplit([0.8, 0.2], seed=71082)\n",
    "\n",
    "# Note: This wouldn't work in a cluster\n",
    "def write_df(df, dirname, filename):\n",
    "    Path = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "    FileSystem = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "    Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "\n",
    "    tmp_name = filename + \".tmp\"\n",
    "    df.coalesce(1).write.mode('overwrite').text(tmp_name)\n",
    "    \n",
    "    fs = FileSystem.get(Configuration())\n",
    "    fs.mkdirs(Path(dirname))\n",
    "    # Assume one file output\n",
    "    file = fs.globStatus(Path(tmp_name + \"/*.txt\"))[0].getPath();\n",
    "    fs.rename(file, Path(dirname + \"/\" + filename));\n",
    "    fs.delete(Path(tmp_name), True);\n",
    "\n",
    "# split training data into positive/negative\n",
    "positive_data = train_data.filter(train_data.Class == \"1\").select(\"norm_text\")\n",
    "write_df(positive_data, \"trumptweet/positive\", \"1.txt\")\n",
    "#positive_data.write.mode(\"overwrite\").text(\"trumptweet/positive\")\n",
    "\n",
    "negative_data = labeled_data.filter(train_data.Class == \"0\").select(\"norm_text\")\n",
    "write_df(negative_data, \"trumptweet/negative\", \"1.txt\")\n",
    "#negative_data.write.mode(\"overwrite\").text(\"trumptweet/negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|                text|Class|           norm_text|  finished_sentiment|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "| you claim you're...|    0|you claim you're ...|    result->negative|\n",
      "|\"Did you know tha...|    0|\"Did you know tha...|    result->negative|\n",
      "|\"Former Reagan An...|    0|\"Former Reagan An...|    result->negative|\n",
      "|\"In 24 days plus ...|    1|\"In 24 days plus ...|result->negative@...|\n",
      "|#DonaldTrump Copi...|    0|Copied  Immigrati...|    result->negative|\n",
      "|#GoogleNews Conse...|    0|Conservative Expe...|    result->negative|\n",
      "|#NYC #News From c...|    1|From campaign to ...|    result->positive|\n",
      "|#Politics Donald ...|    1|Donald Trump: A f...|    result->positive|\n",
      "|#Politics Trump l...|    1|Trump leaves camp...|    result->positive|\n",
      "|#Politics Trump l...|    1|Trump leaves camp...|    result->positive|\n",
      "|#Reuterspolitics ...|    1|Trump leaves camp...|    result->positive|\n",
      "|#Trump agrees wit...|    1|agrees with affir...|result->positive@...|\n",
      "|#Trump, & entire ...|    0|& entire GOP POTU...|    result->negative|\n",
      "|#US #USA BENCHED ...|    1|BENCHED FOR A DAY...|    result->positive|\n",
      "|#dailymail Heidi ...|    0|Heidi Klum fires ...|    result->negative|\n",
      "|#news Trump's Imm...|    1|Trump's Immigrati...|    result->negative|\n",
      "|#oddnews Trump Re...|    1|Trump Reports for...|    result->positive|\n",
      "|#twisters Trump l...|    1|Trump leaves camp...|    result->positive|\n",
      "|'I am Batman,' Tr...|    0|'I am Batman,' Tr...|    result->negative|\n",
      "|.@isaacdovere BRE...|    0|. BREAKING NEWS: ...|    result->negative|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "\n",
    "### Define the dataframe\n",
    "document_assembler = DocumentAssembler().setInputCol(\"norm_text\")\n",
    "    \n",
    "sentence_detector = SentenceDetectorModel().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = RegexTokenizer().setInputCols([\"sentence\"]).setOutputCol(\"token\")\n",
    "        \n",
    "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normal\")        \n",
    "        \n",
    "spell_checker = NorvigSweetingApproach().setInputCols([\"normal\"]).setOutputCol(\"spell\")\n",
    "        \n",
    "sentiment_detector = ViveknSentimentApproach().setInputCols([\"spell\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment\").setPositiveSource(\"trumptweet/positive/1.txt\") \\\n",
    "    .setNegativeSource(\"trumptweet/negative/1.txt\").setPruneCorpus(False) # when training on small data you may want to disable this to not cut off infrequent words\n",
    "    \n",
    "finisher = Finisher().setInputCols([\"sentiment\"]).setIncludeKeys(True)##.setCleanAnnotations(False)\n",
    "    \n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    normalizer,\n",
    "    spell_checker,\n",
    "    sentiment_detector,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "sentiment_data = pipeline.fit(test_data).transform(test_data)    \n",
    "sentiment_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string, Class: string, norm_text: string, finished_sentiment: string, total_sentiment: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def sigmoid(s):\n",
    "    if s is not None:\n",
    "        ls = list(map(lambda x: 1 if (x == \"result->positive\") else 0, s.split(\"@\")))\n",
    "        return 0 if (len(ls) == 0) else round(sum(ls) / len(ls) + .01)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "sigmoid_udf = udf(sigmoid, IntegerType())\n",
    "\n",
    "sentiment_data = sentiment_data.withColumn(\"total_sentiment\", sigmoid_udf(\"finished_sentiment\"))\n",
    "sentiment_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+---------------+\n",
      "|                text|Class|           norm_text|  finished_sentiment|total_sentiment|\n",
      "+--------------------+-----+--------------------+--------------------+---------------+\n",
      "| you claim you're...|    0|you claim you're ...|    result->negative|              0|\n",
      "|\"Did you know tha...|    0|\"Did you know tha...|    result->negative|              0|\n",
      "|\"Former Reagan An...|    0|\"Former Reagan An...|    result->negative|              0|\n",
      "|\"In 24 days plus ...|    1|\"In 24 days plus ...|result->negative@...|              0|\n",
      "|#DonaldTrump Copi...|    0|Copied  Immigrati...|    result->negative|              0|\n",
      "|#GoogleNews Conse...|    0|Conservative Expe...|    result->negative|              0|\n",
      "|#NYC #News From c...|    1|From campaign to ...|    result->positive|              1|\n",
      "|#Politics Donald ...|    1|Donald Trump: A f...|    result->positive|              1|\n",
      "|#Politics Trump l...|    1|Trump leaves camp...|    result->positive|              1|\n",
      "|#Politics Trump l...|    1|Trump leaves camp...|    result->positive|              1|\n",
      "|#Reuterspolitics ...|    1|Trump leaves camp...|    result->positive|              1|\n",
      "|#Trump agrees wit...|    1|agrees with affir...|result->positive@...|              1|\n",
      "|#Trump, & entire ...|    0|& entire GOP POTU...|    result->negative|              0|\n",
      "|#US #USA BENCHED ...|    1|BENCHED FOR A DAY...|    result->positive|              1|\n",
      "|#dailymail Heidi ...|    0|Heidi Klum fires ...|    result->negative|              0|\n",
      "|#news Trump's Imm...|    1|Trump's Immigrati...|    result->negative|              0|\n",
      "|#oddnews Trump Re...|    1|Trump Reports for...|    result->positive|              1|\n",
      "|#twisters Trump l...|    1|Trump leaves camp...|    result->positive|              1|\n",
      "|'I am Batman,' Tr...|    0|'I am Batman,' Tr...|    result->negative|              0|\n",
      "|.@isaacdovere BRE...|    0|. BREAKING NEWS: ...|    result->negative|              0|\n",
      "+--------------------+-----+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8027586206896552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data.filter(sentiment_data.Class == sentiment_data.total_sentiment).count() / sentiment_data.count()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
